\xhdr{Exploration.} Multi-armed bandits (\emph{MAB}) is an elegant and tractable abstraction for tradeoff between \emph{exploration} and \emph{exploitation}: essentially, between acquisition and usage of information. MAB problems have been studied for many decades by researchers from computer science, operations research, statistics and economics, generating a vast and multi-threaded literature.  The most relevant thread concerns the basic model of regret-minimizating bandits with stochastic rewards and no auxiliary structure (which is the problem faced by each principal in our model), see Appendix~\ref{app:bg} for background. This basic model has been extended in many different directions, with a considerable amount of work on each: \eg payoffs with a specific structure (\eg combinatorial, linear, convex or Lipschitz), payoff distributions that change over time, and auxiliary payoff-relevant signals.%
\footnote{There is a superficial similarity, in name only, between this paper and the work on ``dueling bandits" \citep[starting from][]{Yue-dueling12,Yue-dueling-icml09}.
In this work, there is only one bandit algorithm which chooses two arms in each round, and the only observes which arm has ``won the duel".}
Dedicated monographs \citep{Bubeck-survey12,slivkins-MABbook,LS19bandit-book} cover the work on regret-minimizing formulations (which mainly comes from computer science). The classic book
\citep{Gittins-book11} focuses on the Markovian formulations (which predate regret-minimization and were mainly studied in operations research and statistics).
Various connections to economics and game theory are detailed in
books \citep{CesaBL-book,slivkins-MABbook} and surveys \citep{Bergemann-survey06,Horner-survey16}. Industrial applications are discussed in \citep{DS-arxiv}.

The three-way tradeoff between exploration, exploitation and incentives has been studied in mechanism design, in several scenarios very different from ours:
incentivizing exploration in a recommendation system
(starting from \citet{Kremer-JPE14}, see \citet[Ch. 11.6]{slivkins-MABbook} for a literature review),
    %\citep[\eg][]{Che-13,Frazier-ec14,Kremer-JPE14,ICexploration-ec15,Bimpikis-exploration-ms17,Bahar-ec16,Jieming-unbiased18},
dynamic auctions
    (\eg see \citet{DynAuctions-survey10} for a survey),
    %\citep[\eg][]{AtheySegal-econometrica13,DynPivot-econometrica10,Kakade-pivot-or13},
pay-per-click ad auctions
    \citep[\eg][]{MechMAB-ec09,DevanurK09,Transform-ec10-jacm},
coordinating search and matching
    \citep{Bobby-Glen-ec16},
and human computation
    \citep[\eg][]{RepeatedPA-ec14,Ghosh-itcs13,Krause-www13}.
%A literature review of this work can be found in
%\citep[Ch. 11.6]{slivkins-MABbook}.

\xhdr{Exploration and competition.}
\citet{bergemann1997market,bergemann2000experimentation,keller2003price} studied the interplay of exploration and competition for users when the competing firms experiment with \emph{prices}, rather than design alternatives. All three papers consider strategies that respond to competition, and analyze Markov Perfect Equilibria (MPE), whereas we focus on the adoption of better bandit algorithms. We discuss them in more detail below.

In \citet{keller2003price}, the competition is entirely on prices, rather than product quality. This distinction leads to several important differences. First, the data externality -- that each customer brings a new data point to a firm if and only if he chooses this firm -- is absolutely crucial to our setting, and absent in theirs. Second, the inputs to agents' decision rule are prices, rather than the quality of the chosen alternatives; the former is directly controlled by the firms, whereas the latter is not known a priori. Third, the goal of exploration is to learn the agents' decision rule.

The earlier work by \citet{bergemann1997market,bergemann2000experimentation} studies competition on both prices and quality, and allows for the data externality mentioned above. Specifically, the ``entrant" firm offers a new product of unknown, exogenously determined, quality, which is ``explored" if and only if the entrant attracts customers. However, because the entrant can only control the prices but not the product itself, the nature of exploration is fundamentally different. First, the goal of exploration is to reveal information about a fixed product. Second, the entrant can only affect the \emph{quantity} of the said information, but not \emph{which} information is being revealed. Third, revealing more information is not necessarily better for the entrant (if the product's quality is actually low). Fourth, the social planner's exploration problem is very different from the firms', so that when one compares competition to the planner, one can only compare outcomes, but not the algorithms.\footnote{The planner faces a two-armed bandit problem, because the planner can directly choose a firm for each agent.}
% firm, because payments cancel out in social welfare).}



%In \citet{keller2003price}, the competition is entirely on prices, rather than product quality. This distinction leads to several important differences. First, the data externality -- that each customer brings a new data point to a given principal if and only if he chooses this principal -- is absolutely crucial to our setting, and absent in theirs. Second, the inputs to agents' decision rule are prices (which are directly controlled by the principals), rather than the quality of the chosen actions (which is not known a priori). Their focus is on learning the decision rule, whereas ours is on learning product quality. Third, they consider strategies that respond to competition and analyze Markov Perfect Equilibria (MPE), whereas we focus on the adoption of better bandit algorithms.

%\gaedit{\citet{bergemann1997market,bergemann2000experimentation} studied a model where there is an incumbent with known product quality and an entrant with unknown, but exogenously determined, quality. Similar to \citet{keller2003price}, the firms compete on prices and they characterize the MPE of dynamic competition between the two firms. In their model, consumer purchases of the entrant's product result in an informational externality that allows both the firms and consumers to gather information on the entrant's product quality. However, we focus on a model where firms' product quality is endogenous and the focus of exploration in a context where the price mechanism is absent.}
In the line of work on \emph{strategic experimentation} (starting from \citet{Bolton-econometrica99,Keller-econometrica05}, see \citet{Horner-survey16} for a survey), agents explore and learn over time in a shared environment. Thus, we have exploration algorithms which interact with each other strategically, \eg each agent would prefer to free-ride on the exploration done by others. However, the agents do not compete with each other in any meaningful sense.

Several papers study competition between two principals who run algorithms but do not interact, directly or indirectly, until the very end of the game. \cite{Ufuk-jeea15} consider a ``research competition" between two firms racing towards a big discovery.
Each firm deploys a bandit algorithm with two arms, corresponding to safe and risky lines of research. The firms do not interact until one of them makes the discovery and wins the game. In the ``dueling algorithms" framework of \citet{DuelingAlgs-stoc11}, each principals runs an algorithm for the same problem. All inputs are observable at once, and principals' payoffs are binary (win/lose). \citet{ben2017best, ben2019regression} study competition between ``offline" machine learning algorithms. In comparison, we study a ``product competition" in which the two firms interact continuously (via the customers' choices), accrue rewards incrementally, and compete for individual customers.


A long line of work from electrical engineering and computer science, starting from
\citet{MultiPlayerMAB-Poor08,MultiPlayerMAB-Liu10,MultiPlayerMAB-Anima11}, focuses on competition for resources, not competition for consumers. Specifically, this literature targets an application to \emph{cognitive radios}, where multiple radios transmit simultaneously in a shared medium and compete for bandwidth. Each radio chooses channels over time using a multi-armed bandit algorithm. This work studies a repeated game between bandit algorithms, and focuses on designing algorithms which work well in this game, under various assumptions on communication, synchronization and collisions.




%and continuing to, \eg \citet{MultiPlayerMAB-Mannor14,MultiPlayerMAB-Shamir-icml16,MultiPlayerMAB-Perchet-18,MultiPlayerMAB-Sellke-19}.


\xhdr{Competition.} The competition vs. innovation relationship and the inverted-U shape thereof have been introduced in a classic book \citep{Schumpeter-42}, and remained an important theme in the literature ever since \cite[\eg][]{aghion2005competition,Vives-08}. Production costs aside, this literature treats innovation as a priori beneficial for the firm. Our setting is very different, as innovation in exploration algorithms may potentially hurt the firm.

The literature on learning-by-doing vs. competition \citep[\eg][]{fudenberg1983learning, dasgupta1988learning, cabral1994learning} studies firms that learn while competing against each other, so that a firm attracting more consumers reduces its per-unit production costs. \gaedit{However, our model differs from these models in two important respects. The first is that in our model firms focus on learning product quality (as opposed to reducing production costs) and the second is that firms' current period actions have reputational consequences that directly impact consumer choices in future periods. These features are absent from traditional learning-by-doing models, but important components of a model that tries to capture data-based innovation.}

A line of work on \emph{platform competition} (starting with \cite{Rysman09}, see \citet{Weyl-White-14} for a survey) concerns competition between firms that improve as they attract more users. This literature is not concerned with \innovation, and typically models network effects exogenously, whereas they are endogenous in our model.
%: they are created by MAB algorithms, an essential part of the model.
A nascent literature studies
%whether and when network effects manifest themselves
network effects
in data-intensive markets \citep{prufer2017competing, hagiu2020data}, but typically models learning as a reduced-form function of past consumer history and focuses on the role of prices.
%as opposed to the reputational consequences of learning.

\cite{schmalensee1982product, bagwell1990informational} investigate how buyer uncertainty about product quality can serve as a barrier to entry for late arrivers; we find a similar effect with ``reputation advantage". The role of data as a barrier to entry in online markets has been noted in \cite{de2020data}; we find a similar effect with ``data advantage". \citet{kerin1992first} overview the other channels through which first-mover advantage can lead to a competitive advantage.


%\cite{schmalensee1982product, bagwell1990informational} investigate how buyer uncertainty about product quality can serve as a barrier to entry for late arrivers. We observe a similar effect when we investigate the role that reputation can serve as a barrier to entry. In our model the first-mover advantage further provides the incumbent with a ``head start" on data collection relative to the late arrivers. Thus, our model also highlights the role that data can serve as a barrier to entry in online markets which has similarly been noted in \cite{de2020data}. For an extensive overview of the other channels through which first-mover advantages can lead to a competitive advantage, see \cite{kerin1992first}.

%We use first-mover advantage and \asedit{agents' decision rule}
%relaxed versions of rationality
%to model varying competition, instead of

Classic ``market competitiveness" measures,such as the Lerner Index or the Herfindahl-Hirschman Index
\citep{tirole1988theory} are not applicable to our setting, as they rely on ex-post observable market attributes such as prices or market shares (which are, resp., absent and endogenous for us).

%Neither is applicable to our setting (since there are no prices, and market shares are endogenous).


\xhdr{Choice models.}
Stochastic choice models similar to ours have been widely used throughout economics. First, ``random agents" (a.k.a. noise traders) can side-step the ``no-trade theorem'' \citep{Milgrom-Stokey-82}, a famous impossibility result in financial economics. They play a similar role in our model, side-stepping the dominance of the greedy algorithm.
%as we move from \HardMax to \HardMaxRandom.
Second, there a large literature on non-existence of equilibria due to small deviations, starting with \cite{Rothschild-Stiglitz-76} in the context of health insurance markets.\footnote{\cite{Veiga-Weyl-16,Azevedo-Gottlieb-17} emphasize the distinction between \HardMax and versions of \SoftMaxRandom in this context.}
This is superficially similar to how small deviations towards the greedy algorithm rule out equilibria under \HardMaxRandom.
%Second, the stochastic choice rules we consider have been widely utilized across economics. For instance,
Third, \SoftMaxRandom subsumes the logit choice rule, a standard behavioral model with strong empirical and microeconomic foundations
\citep[\eg][]{mosteller1951experimental, luce1959choice, mcfadden1974measurement, matvejka2015rational}.
Fourth, choice models similar to \SoftMaxRandom are used to explain  horizontal product differentiation \citep[\eg][]{Hotelling-29, Perloff-Salop-85}.
%\asdelete{While agents' rationality and severity of competition are often modeled separately in the literature, it is not unusual to have them modeled with the same ``knob" \cite[\eg][]{Gabaix-16}.}


%%% Local Variables:
%%% TeX-master: "main.tex"
%%% End: 